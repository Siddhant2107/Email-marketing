ğŸ“§ Email Campaign Optimization
This project analyzes an email marketing campaign to uncover what drives user engagement and builds a machine learning model to predict click-through probability, guiding future targeting strategies.

*Main file -- first.ipynb*

âœ… Project Goals

âœ”ï¸ Analyze open and click-through behavior across email campaigns

âœ”ï¸ Understand the impact of email content, personalization, timing, user demographics, and purchase history

âœ”ï¸ Engineer relevant features (e.g., cyclical time encoding, log-transform for skewed variables)

âœ”ï¸ Build and evaluate machine learning models (Logistic Regression, Random Forest, XGBoost, LightGBM)

âœ”ï¸ Optimize threshold to maximize F1 score and click prediction

âœ”ï¸ Derive key actionable insights to inform future marketing strategies

âœ”ï¸ Provide an implementation plan for real-world deployment

âœ… Summary of Key Insights

ğŸ•’ Timing Optimization
âœ”ï¸ Best hours to send: 23:00, 00:00, 10:00

âœ”ï¸ Worst hours: 18:00 - 22:00

âœ”ï¸ Best days: Wednesday, Tuesday

âœ‰ï¸ Email Content

âœ”ï¸ Short emails outperform long ones

âœ”ï¸ Personalized emails drive significantly higher CTR

âœ”ï¸ Personalization works especially well for high-value customers

ğŸŒ Geographic Performance

âœ”ï¸ Top performing countries (by CTR): UK > US > ES > FR

ğŸ›ï¸ User Segmentation (Purchase History)

âœ”ï¸ Customers with 6+ purchases had highest engagement

âœ”ï¸ CTR improves consistently with more past purchases

âœ… Modeling Results

âœ”ï¸ Used SMOTE to balance classes due to low click-through rate (~2.1%)

âœ”ï¸ Evaluated multiple models using ROC AUC, PR AUC, and F1-score

âœ”ï¸ Best model: XGBoost, tuned with cross-validation

âœ”ï¸ Applied optimal probability threshold using Precision-Recall curve

âœ… Performance Improvement Estimate

âœ”ï¸ By targeting the top 50% of users based on model score, we can achieve a ~65.1% increase in click-through rate

âœ”ï¸ Model-based targeting boosts CTR from 2.1% â†’ ~3.48%

âœ… How to Test This in Production

âœ”ï¸ Phase 1: Score users using the model

âœ”ï¸ Phase 2: Send emails only to top 50% of predicted high-CTR users

âœ”ï¸ Phase 3: Conduct A/B test comparing model-selected users vs random users

âœ”ï¸ Phase 4: Measure actual CTR lift to validate model predictions

âœ”ï¸ Phase 5: Iterate with new campaign data

âœ… Answers to Key Business Questions

ğŸ’¬ "The VP of marketing thinks it's stupid to send emails randomly. Can you build a model to optimize this?"
âœ”ï¸ Yes! We've built a model that predicts the probability of a user clicking an email based on historical behavior, demographics, email content, and timing.
âœ”ï¸ It allows intelligent targeting instead of random sends â€” maximizing ROI and user engagement.

ğŸ’¡ "By how much could this model improve CTR? How would you test it?"

âœ”ï¸ Our model identifies the top 50% of users with highest predicted CTR.
âœ”ï¸ When targeting these users, we estimate a 65.1% increase in CTR.
âœ”ï¸ We'd test this through an A/B test comparing:

Group A: Emails sent using the model

Group B: Emails sent at random
âœ”ï¸ Track CTR across both groups to validate uplift.

ğŸ” "Did you find any interesting patterns by user segments?"
âœ”ï¸ Yes, multiple patterns:

ğŸ“ˆ High purchase history users (6+ past purchases) have significantly higher CTR

ğŸ“¬ Personalized emails work better across the board

ğŸŒ Some countries (e.g., UK, US) outperform others â€” consider localized content

ğŸ•’ Send emails late at night or in the morning for better engagement

ğŸ“„ Keep emails short and to the point

âœ… Final Recommendations

âœ”ï¸ Use the model to score and target the top 50% of your audience

âœ”ï¸ Focus on personalized, short emails for maximum engagement

âœ”ï¸ Prioritize high-value customers (6+ past purchases)

âœ”ï¸ Send emails between 23:00 - 11:00, especially on Tuesdays and Wednesdays

âœ”ï¸ Prioritize regions like UK and US for better ROI

âœ”ï¸ Roll out in phases with continuous monitoring
